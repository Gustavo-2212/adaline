# Projeto de Aprendizado de MÃ¡quina com Redes Multicamadas ğŸ§ 
---
### Autor
- **Nome:** Gustavo Alves de Oliveira
- **MatrÃ­cula:** 12311ECP026
- **Disciplina:** Aprendizagem de MÃ¡quina
- **Faculdade:** Universidade Federal de UberlÃ¢ndia


ğŸ¤–ğŸ“ŠğŸ”

Este projeto utiliza tÃ©cnicas de Aprendizado de MÃ¡quina para calcular a funÃ§Ã£o aproximada que passa por todos os pontos de um conjunto de amostras dado.

### Redes Neurais Perceptrons de Multicamadas (MLP)

As Redes Neurais Perceptrons de Multicamadas (MLPs) sÃ£o uma classe de redes neurais artificiais que consistem em uma rede de nÃ³s (neurÃ´nios) organizados em camadas. As MLPs sÃ£o compostas por uma camada de entrada, uma ou mais camadas ocultas e uma camada de saÃ­da.

### Funcionamento das MLPs:

1. **Camada de Entrada:**
   - Os nÃ³s na camada de entrada representam as caracterÃ­sticas (features) dos dados de entrada. Cada nÃ³ nesta camada corresponde a uma caracterÃ­stica especÃ­fica.

2. **Camadas Ocultas:**
   - As camadas ocultas sÃ£o compostas por neurÃ´nios que processam os dados de entrada e aprendem a representaÃ§Ã£o dos padrÃµes nos dados.
   - Cada neurÃ´nio em uma camada oculta recebe entradas das camadas anteriores, realiza uma combinaÃ§Ã£o linear das entradas ponderadas por pesos, aplica uma funÃ§Ã£o de ativaÃ§Ã£o nÃ£o linear e passa o resultado para as camadas posteriores.
   - A presenÃ§a de camadas ocultas permite que as MLPs aprendam representaÃ§Ãµes mais complexas e nÃ£o lineares dos dados.

3. **Camada de SaÃ­da:**
   - A camada de saÃ­da produz a saÃ­da final da rede neural. A estrutura desta camada depende do tipo de problema que estÃ¡ sendo abordado, como classificaÃ§Ã£o (por exemplo, softmax para classificaÃ§Ã£o multiclasse) ou regressÃ£o (um Ãºnico neurÃ´nio de saÃ­da para prever um valor contÃ­nuo).

>![MLP](https://www.researchgate.net/publication/293013889/figure/fig1/AS:335717596188674@1457052720824/Figura-1-Exemplo-simplificado-de-uma-rede-neural-multicamadas-HAYKIN-2001-Figure-1.png)

### IdealizaÃ§Ã£o e Desenvolvimento:

As MLPs nÃ£o tÃªm um Ãºnico idealizador. O desenvolvimento das MLPs foi uma evoluÃ§Ã£o das redes neurais perceptrons originais propostas por Frank Rosenblatt em 1957. As MLPs foram introduzidas para superar a limitaÃ§Ã£o das redes perceptrons de uma Ãºnica camada, que sÃ³ podiam resolver problemas linearmente separÃ¡veis. A ideia de adicionar camadas ocultas e usar algoritmos de treinamento como o backpropagation permitiu que as MLPs aprendessem a representar relaÃ§Ãµes mais complexas nos dados.

### FunÃ§Ã£o SigmÃ³ide Bipolar como FunÃ§Ã£o de AtivaÃ§Ã£o:

A funÃ§Ã£o sigmÃ³ide bipolar, tambÃ©m conhecida como funÃ§Ã£o de ativaÃ§Ã£o bipolar, Ã© uma funÃ§Ã£o matemÃ¡tica usada em redes neurais como uma funÃ§Ã£o de ativaÃ§Ã£o. Sua fÃ³rmula Ã©:

\[ f(x) = \frac{2}{1 + e^{-x}} - 1 \]

Esta funÃ§Ã£o mapeia os valores de entrada para o intervalo [-1, 1]. Ela Ã© suave e diferenciÃ¡vel em todos os pontos, o que a torna adequada para o treinamento de redes neurais utilizando algoritmos de otimizaÃ§Ã£o baseados em gradiente, como o backpropagation.

A funÃ§Ã£o sigmÃ³ide bipolar tem sido historicamente utilizada como funÃ§Ã£o de ativaÃ§Ã£o nos neurÃ´nios das camadas ocultas das MLPs. No entanto, devido a problemas como o desaparecimento do gradiente durante o treinamento profundo e a propagaÃ§Ã£o do gradiente muito lenta em camadas profundas, funÃ§Ãµes de ativaÃ§Ã£o alternativas, como ReLU (Rectified Linear Unit) e suas variantes, tornaram-se mais populares em redes neurais profundas modernas.

> ![SigmÃ³ide Bipolar](https://www.researchgate.net/publication/331087209/figure/fig4/AS:726046831820800@1550114462005/Figura-54-Funcion-de-Activacion-Sigmoide-Bipolar.jpg)

### Estrutura do Projeto

O projeto estÃ¡ estruturado da seguinte forma:

- **./graph**: ResponsÃ¡vel pela geraÃ§Ã£o dos grÃ¡ficos interativos usando a biblioteca Bokeh.
- **./src**: ContÃ©m os cÃ³digos-fonte, incluindo `main.py` como o arquivo executÃ¡vel principal.

### DependÃªncias do Projeto

Para executar o projeto, Ã© necessÃ¡rio instalar a seguinte biblioteca Python:

- Bokeh: Biblioteca para criar visualizaÃ§Ãµes interativas em navegadores da web.

```bash
pip install bokeh
```

### Como Executar o Projeto

1. Clone o repositÃ³rio do projeto.
2. Instale as dependÃªncias listadas acima.
3. Execute o arquivo `main.py` dentro da pasta `./src` para gerar os grÃ¡ficos e realizar as anÃ¡lises estatÃ­sticas.

### ConclusÃµes

Podemos ver que a funÃ§Ã£o consegue aproximar bem dos pontos das amostras. O que ainda podemos testar sÃ£o outros tipos de arquiteturas de redes neurais, bem como outras funÃ§Ãµes de ativaÃ§Ã£o, verificando se o desempenho da rede neural Ã© melhorado ou nÃ£o.

ğŸš€ğŸ”ğŸ’¡

---
